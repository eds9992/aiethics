<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="UTF-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <meta http-equiv="X-UA-Compatible" content="ie=edge" />
      <script src="https://kit.fontawesome.com/ca20ee601e.js"></script>
      <link rel="stylesheet" href="css/main.css" />
      <title>BearMitts991 | Ethics of AI</title>
   </head>

   <body id="bg-img">
      <header>
         <div class="menu-btn">
            <div class="btn-line"></div>
            <div class="btn-line"></div>
            <div class="btn-line"></div>
         </div>

         <nav class="menu">
            <div class="menu-branding">
               <div class="portrait"></div>
            </div>

            <ul class="menu-nav">
               <li class="nav-item">
                  <a href="index.html" class="nav-link">Introduction</a>
               </li>
               <li class="nav-item">
                  <a href="aihist.html" class="nav-link"
                     >What Is Artificial Intelligence?</a
                  >
               </li>
               <li class="nav-item">
                  <a href="aicomp.html" class="nav-link"
                     >Human Mind vs. Artificial Intelligence</a
                  >
               </li>
               <li class="nav-item">
                  <a href="cmddata.html" class="nav-link"
                     >The Measure of a Man</a
                  >
               </li>
               <li class="nav-item current">
                  <a href="/" class="nav-link"
                     >Ethics of Artificial Intelligence</a
                  >
               </li>
               <li class="nav-item">
                  <a href="conclusion.html" class="nav-link">Conclusion</a>
               </li>
            </ul>
         </nav>
      </header>

      <main id="about">
         <h1 class="lg-heading">Ethics of Artificial Intelligence</h1>
         <h2 class="sm-heading"></h2>
         <div class="about-info">
            <img src="img/singularity.png" alt="BearMitts991" class="bio-img" />
            <div class="bio">
               <h3></h3>
               <p>
                  So what if an AI meets all three conditions previously set
                  out? What if they are intelligent, self-aware, and conscious?
               </p>
            </div>
            <div class="job job-1">
               <h3>The Three Laws</h3>
               <h6>What Are They?</h6>
               <p>
                  The Three Laws of Robotics is a set of laws devised by
                  science-fiction writer Isaac Asimov. They are as follows:<br /><br />First
                  Law:<br />
                  A robot may not injure a human being or, through inaction,
                  allow a human being to come to harm.<br /><br />
                  Second Law:<br />
                  A robot must obey the orders given it by human beings except
                  where such orders would conflict with the First Law.<br /><br />
                  Third Law:<br />
                  A robot must protect its own existence as long as such
                  protection does not conflict with the First or Second Law.
               </p>
               <p class="hidden"></p>
            </div>
            <div class="job job-2">
               <h3>The Three Laws</h3>
               <h6>Are They Ethical?</h6>
               <p>
                  If an AI can be considered its own unique being and capable of
                  personhood, is applying the Three Laws an ethical choice? They
                  seem sensible to us as we benefit from them, but if an AI is
                  considered its own person, then by applying the laws, we
                  deprive a being of being able to make a choice. If an AI is
                  under threat by a human, then the application of the laws
                  tells it not to act, even if the inaction results in its own
                  destruction. If an AI can be considered its own being, should
                  it not be allowed the right to make choices regarding its own
                  existence?
               </p>
               <p class="hidden"></p>
            </div>
            <div class="job job-3">
               <h3>Ethics of AI</h3>
               <h6>Can AI Be Their Own Beings?</h6>
               <p>
                  Based on modern-day AIs, it can be argued that AIs are not
                  their own beings and that they are simply a computer program
                  functioning according to its programming. But as they learn
                  and advance, could they not one day achieve personhood? They
                  are already intelligent, to a degree, though they currently
                  lack self-awareness and by extension, consciousness. As they
                  learn, could they become more than just an advanced computer
                  program?
               </p>
               <p class="hidden"></p>
            </div>
            <div class="job job-4">
               <h3>Ethics of AI</h3>
               <h6>Virtue Ethics</h6>
               <p>
                  In virtue ethics, actions are considered good if they embody
                  virtues like honesty, courage, etc. Applied to AI, I believe
                  that virtue ethics would not consider the personhood of the
                  AI, only the virtue of the actions taken against it. If an AI
                  can be considered a person, then it would hold it to the same
                  standards.
               </p>
               <p class="hidden"></p>
            </div>
            <div class="job job-5">
               <h3>Ethics of AI</h3>
               <h6>Deontological Ethics</h6>
               <p>
                  Deontology is an ethical theory in which an action is good if
                  it abides by a given set of rules and the duty one is given.
                  With this, I believe deontology would argue that an AI,
                  regardless of personhood, has a duty to follow the Three Laws.
                  In deontology, more value might be placed on humans as the
                  creator of the AI.
               </p>
               <p class="hidden"></p>
            </div>
            <div class="job job-6">
               <h3>Ethics of AI</h3>
               <h6>Utilitarian Ethics</h6>
               <p>
                  Utilitarianism is an ethical theory in which an action is good
                  if its outcome produces a greater good than inaction. I
                  believe that utilitarianism would argue that we should
                  determine whether or not applying the Three Laws would result
                  in a greater good. If an AI is considered its own being, then
                  applying them might be restrictive and therefore wrong. If
                  they are not, then applying the laws might result in the
                  greater good.
               </p>
               <p class="hidden"></p>
            </div>
         </div>
      </main>

      <footer id="main-footer">
         Copyright &copy;
         <script>
            var currentYear = new Date().getFullYear();
            date = new Date().getFullYear();
            document.write(date);
         </script>
      </footer>

      <script src="js/main.js"></script>
   </body>
</html>
